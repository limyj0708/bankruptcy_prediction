{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "from IPython.display import clear_output # Cell output clear를 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_article_list_gen = pd.read_csv('seoulK.csv', encoding='utf-8', chunksize=20000, dtype={'종목코드': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv_one_article(one_dict, header_list):\n",
    "    if os.path.isfile('seoulK_with_body.csv'): # 파일이 있는지 확인\n",
    "        open_param = 'a' # 있으면 수정(뒤에 내용 추가) 모드\n",
    "    else:\n",
    "        open_param = 'w' # 없으면 파일 생성함\n",
    "            \n",
    "    with open('seoulK_with_body.csv', open_param, encoding='utf-8', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        if open_param == 'w':\n",
    "            wr.writerow(header_list)\n",
    "            \n",
    "        writerow_pa_list = []\n",
    "        \n",
    "        for each_key in one_dict:\n",
    "            writerow_pa_list.append(one_dict[each_key])\n",
    "        wr.writerow(writerow_pa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_article_body(article_url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(article_url, headers={'user-agent': 'Mozilla/5.0'}) as req:\n",
    "            if req.status == 404:\n",
    "                print('그런 페이지가 없다')\n",
    "                return None # 없는 페이지라면 반환값은 None이 된다.\n",
    "            html = await req.text()\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            article_body = soup.find('div', {\"itemprop\" : \"articleBody\"}).get_text()\n",
    "            return article_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article_list_gen = pd.read_csv('seoulK2.csv', encoding='utf-8', chunksize=20000, dtype={'종목코드': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'언론사명'</th>\n",
       "      <th>'회사명'</th>\n",
       "      <th>'종목코드'</th>\n",
       "      <th>'기사_URL'</th>\n",
       "      <th>'기사_업로드_날짜'</th>\n",
       "      <th>'기사_제목'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>한일건설</td>\n",
       "      <td>6440</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HW01D27QC</td>\n",
       "      <td>2012-02-27</td>\n",
       "      <td>[리포트] GS글로벌, 자회사 디케이티 올 흑자전환 - 현대證\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>한일건설</td>\n",
       "      <td>6440</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HOITWL5HX</td>\n",
       "      <td>2012-02-26</td>\n",
       "      <td>표류 공모형 PF사업 정상화 나선다\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>한일건설</td>\n",
       "      <td>6440</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HLMGZHI6Q</td>\n",
       "      <td>2012-02-26</td>\n",
       "      <td>[전국 패트롤] 인천亞게임 선수촌 건설 공사 내달 23일 첫 삽\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>한일건설</td>\n",
       "      <td>6440</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HTLKSF75G</td>\n",
       "      <td>2012-02-26</td>\n",
       "      <td>대구 건설업계 기지개\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>한일건설</td>\n",
       "      <td>6440</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HPLA86YII</td>\n",
       "      <td>2012-02-26</td>\n",
       "      <td>[분양하이라이트] 대우건설 광교 '푸르지오 월드마크' 청약\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>경남은행</td>\n",
       "      <td>192520</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HQREO56G6</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>[오늘의 메모] 6월 2일\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>경남은행</td>\n",
       "      <td>192520</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HNB5884XS</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>경남은행 \"BNK그룹 편입 효과 있네\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>경남은행</td>\n",
       "      <td>192520</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HVU4838GO</td>\n",
       "      <td>2015-05-29</td>\n",
       "      <td>[서울포럼 2015] 참석해주신 분들\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>경남은행</td>\n",
       "      <td>192520</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HTK1DCKCQ</td>\n",
       "      <td>2015-05-26</td>\n",
       "      <td>네이버페이 다음 달 25일 출시\"\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>서울경제</td>\n",
       "      <td>경남은행</td>\n",
       "      <td>192520</td>\n",
       "      <td>https://www.sedaily.com/NewsView/1HRA99CBLK</td>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>'BNK금융, GS운용 인수' 반년째 스톱\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      '언론사명' '회사명'  '종목코드'                                     '기사_URL'  \\\n",
       "0       서울경제  한일건설    6440  https://www.sedaily.com/NewsView/1HW01D27QC   \n",
       "1       서울경제  한일건설    6440  https://www.sedaily.com/NewsView/1HOITWL5HX   \n",
       "2       서울경제  한일건설    6440  https://www.sedaily.com/NewsView/1HLMGZHI6Q   \n",
       "3       서울경제  한일건설    6440  https://www.sedaily.com/NewsView/1HTLKSF75G   \n",
       "4       서울경제  한일건설    6440  https://www.sedaily.com/NewsView/1HPLA86YII   \n",
       "...      ...   ...     ...                                          ...   \n",
       "19995   서울경제  경남은행  192520  https://www.sedaily.com/NewsView/1HQREO56G6   \n",
       "19996   서울경제  경남은행  192520  https://www.sedaily.com/NewsView/1HNB5884XS   \n",
       "19997   서울경제  경남은행  192520  https://www.sedaily.com/NewsView/1HVU4838GO   \n",
       "19998   서울경제  경남은행  192520  https://www.sedaily.com/NewsView/1HTK1DCKCQ   \n",
       "19999   서울경제  경남은행  192520  https://www.sedaily.com/NewsView/1HRA99CBLK   \n",
       "\n",
       "      '기사_업로드_날짜'                                '기사_제목'  \n",
       "0      2012-02-27    [리포트] GS글로벌, 자회사 디케이티 올 흑자전환 - 현대證\"  \n",
       "1      2012-02-26                  표류 공모형 PF사업 정상화 나선다\"\"  \n",
       "2      2012-02-26  [전국 패트롤] 인천亞게임 선수촌 건설 공사 내달 23일 첫 삽\"\"  \n",
       "3      2012-02-26                          대구 건설업계 기지개\"\"  \n",
       "4      2012-02-26     [분양하이라이트] 대우건설 광교 '푸르지오 월드마크' 청약\"\"  \n",
       "...           ...                                    ...  \n",
       "19995  2015-06-01                       [오늘의 메모] 6월 2일\"\"  \n",
       "19996  2015-06-01                 경남은행 \"BNK그룹 편입 효과 있네\"\"  \n",
       "19997  2015-05-29                 [서울포럼 2015] 참석해주신 분들\"\"  \n",
       "19998  2015-05-26                    네이버페이 다음 달 25일 출시\"\"  \n",
       "19999  2015-05-21               'BNK금융, GS운용 인수' 반년째 스톱\"  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(df_article_list_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_article_body_run(df_article_list_gen):\n",
    "    try: # pickle 파일 있는지 없는지 확인\n",
    "        with open('progress_getbody.pickle', 'rb') as f:\n",
    "            last_progress_getbody = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        last_progress_getbody = [0,0]\n",
    "        # 몇 번째 chunk인지, chunk 내에서 몇 번째인지 설정\n",
    "\n",
    "    header = ['언론사명', '회사명', '종목코드', '기사_URL', '기사_업로드_날짜', '기사_제목', '기사_내용']\n",
    "    \n",
    "    progress_chunk = 0\n",
    "    for each_chunk in df_article_list_gen:\n",
    "        clear_output(wait=True)\n",
    "        if last_progress_getbody[0] > progress_chunk:\n",
    "            progress_chunk += 1\n",
    "            continue\n",
    "        \n",
    "        idx = 0\n",
    "        loop_check = 1\n",
    "        progress_inside_chunk = 0\n",
    "        \n",
    "        while loop_check == 1:\n",
    "            if last_progress_getbody[1] > progress_inside_chunk:\n",
    "                progress_inside_chunk += 1\n",
    "                idx += 1\n",
    "                continue\n",
    "            \n",
    "            for _ in range(1,11):\n",
    "                get_article_body_ins_list = []\n",
    "                article_dict_list = []\n",
    "                try:\n",
    "                    article_dict = {}\n",
    "                    for each_key in header:\n",
    "                        if each_key != '기사_내용':\n",
    "                            article_dict[each_key] = test_df.iloc[idx][each_key]\n",
    "                        else:\n",
    "                            article_dict[each_key] = None\n",
    "\n",
    "                    article_dict_list.append(article_dict)\n",
    "                    get_article_body_ins_list.append(get_article_body(article_dict['기사_URL']))\n",
    "                    idx += 1\n",
    "                except KeyError:\n",
    "                    loop_check = 0\n",
    "                    break\n",
    "\n",
    "            body_bunch = await asyncio.gather(*get_article_body_ins_list)\n",
    "\n",
    "            for idx, each in enumerate(article_dict_list):\n",
    "                each['기사_내용'] = body_bunch[idx]\n",
    "                save_to_csv_one_article(each, header)\n",
    "                \n",
    "            last_progress_getbody[1] = last_progress_getbody[1] + len(body_bunch)\n",
    "            with open('progress_getbody.pickle', 'wb') as f:\n",
    "                pickle.dump(last_progress_getbody, f)\n",
    "            \n",
    "            print(last_progress_getbody[0], last_progress_getbody[1])\n",
    "            time.sleep(1)\n",
    "\n",
    "        last_progress_getbody[0] += 1\n",
    "        last_progress_getbody[1] = 0\n",
    "        with open('progress_getbody.pickle', 'wb') as f:\n",
    "            pickle.dump(last_progress_getbody, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b713ba59bdf5>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e213acbcc529>\u001b[0m in \u001b[0;36mget_article_body_run\u001b[0;34m(df_article_list_gen)\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0meach_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0meach_key\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'기사_내용'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                             \u001b[0marticle_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                             \u001b[0marticle_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "await get_article_body_run(df_article_list_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 없애야 할 텍스트 목록\n",
    " # googletag.cmd.push(function() { googletag.display('div-gpt-ad-1567043459465-0'); });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1530]\n"
     ]
    }
   ],
   "source": [
    "with open('progress_getbody.pickle', 'rb') as f:\n",
    "    last_progress_getbody = pickle.load(f)\n",
    "    print(last_progress_getbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seoulK.csv', 'r', encoding='utf-8', newline='') as f:\n",
    "    rdr= csv.reader(f)\n",
    "    with open('seoulK2.csv', 'w', encoding='utf-8', newline='') as wf:\n",
    "        wtr= csv.writer(wf)\n",
    "        for r in rdr:\n",
    "            wtr.writerow( (r[0], r[1], r[2], r[3], r[4], r[5]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
